---
title: "Power Analysis"
output:
  html_document:
    df_print: paged
---

## **Power Analysis Details**
We perform a power analysis for QTLs using our simulations. We are asking two main questions. At what effect size do you detect 80% of true positives in genes that have 1 UMI/cell and 1k cells? At that same effect size, what about 2 UMI/cell in 500 cells? 0.5 UMI/cell in 2000 cells? Additionally, at the same effect size, what about across different numbers of individuals?

## **Simulations at 1000 cells and 1 UMI/cell**

Under the simulation framework for $i$ cells and $j$ genes: $E[X] = L_i\alpha_j\sigma_j$ and $Var(X) =L_i\alpha_j\sigma_j + L_i^2 \alpha_j\sigma_j^2$, where $L$ is the library size and $\alpha, \sigma$ are the shape and scale parameters. To increase the dispersion level we multiply $\sigma$ by an applied factor. We assume a fixed library size for all cells. We can set the target of 1 UMI/cell by setting the expectation equal to 1 for a fixed $L,\alpha, \text{and } \sigma$.

### ***Estimating $\phi$***

We use the HDC dataset and look at the cardiomyocyte cell type. We pool genes that have mean expression of between 0.9 - 1.1 UMI/cell and fit a Gamma-Poisson model to estimate $\phi$.


```{r,warning=F,message=F}
library(glmGamPoi)
library(dplyr)

card_path = "/project/gilad/brendan/dispersion/pilot/cHDC_data/cellranger_cluster-mode_trial/analysis/datasets/median_gene_detection/"
#setwd(card_path)


cardiomyocytes_data4000 <- readRDS(paste(card_path, "lane_a_card_downsampled_UMI_matrix_10.rds", sep = ""))
cardiomyocytes_data4000 <- t(as.matrix(cardiomyocytes_data4000))

# calculate mean expression and remove genes with low expression
cardiomyocytes_data4000_filtered <- cardiomyocytes_data4000[, colSums(cardiomyocytes_data4000 != 0) > 10]

# calculate mean expression
mean_expression4000 <- colMeans(cardiomyocytes_data4000_filtered)
```

We group the genes within 0.9-1.1 UMI/cell. There are 778 genes.
```{r}
# get indices for genes within bin of mean expression
mean_idx <- which(between(mean_expression4000,0.9,1.1)) 
grouped_data <- as.vector(cardiomyocytes_data4000_filtered[,mean_idx])
length(mean_idx)
```

Of these genes we also get an estimate of the average library size and use this as the fixed library size in the simulations.

```{r}
avg_li <- mean(colSums(cardiomyocytes_data4000_filtered[,mean_idx]))
avg_li
```

We now fit the Gamma-Poisson to the pooled data and estimate $\phi$.
```{r}
# fit gamma-poisson distribution
fit_gp <- glm_gp(grouped_data, size_factors=1)
sum_gp <- summary(fit_gp)
phi <- sum_gp$overdispersions
phi
```

### ***Set $L, \alpha, \sigma$***

We estimate the Gamma-Poisson values using **glmGamPoi**:
$$
E[X] = \mu \hspace{20 mm} Var[X] = \mu + \mu^2\phi
$$

Under the simulation framework:
$$
E[X] = L_i\alpha_j\sigma_j \hspace{20 mm} Var(X) =L_i\alpha_j\sigma_j + L_i^2 \alpha_j\sigma_j^2
$$

Setting the expectation and variance equations equal to each other, we get:
$$
\sigma = \frac{\mu\phi}{L} \hspace{20 mm} \alpha = \frac{1}{\phi}
$$

We know that $\mu = 1$ since we are targeting 1 UMI/cell. We multiply $L_i\alpha_j\sigma_j$ to double check that it equals 1.
```{r}
mu <- 1

sigma <- mu*phi/avg_li
alpha <- 1/phi

sigma*alpha*avg_li
```

### ***Simulate at varying dispersion levels***

For a fixed mean of 1 UMI/cell we want to test different effect sizes. We assess different effect sizes by varying the applied factor from: 1,1.1,1.2,...,2. We will do this and test across different individuals per group: 1, 2, 3, ... , 25. Since we are testing for 1000 cells/individual we can pool all cells for individuals. For example, 25 individuals/group would be 25,000 cells in the null variance group and 35,000 cells in the effect size group for a total of 50 individuals.

```{r}
sim_gene <- function(n,alpha,sigma,Li, sigma_multiplier=1){

  # Simulate a single gene with following parameters:
  # n:                number of cells
  # alpha:            alpha parameter
  # sigma:            sigma parameter
  # Li:               library size
  # sigma_multiplier: factor to increase variance
 
  # Returns expression values for single gene in n cells
  
  # initialize Y
  Y <- rep(NA,n) 
  
  # calculate latent expression using gamma distribution
  # ensure that simulation has mean within 10% of target
  # perc_diff = 1
  # while(perc_diff > 0.05){
  lambdaj <- rgamma(n,shape = alpha/sigma_multiplier,scale = sigma*sigma_multiplier)
  # perc_diff = (alpha*sigma - mean(lambdaj))/alpha*sigma
  # }

  
  #lambdaj <- rgamma(n,shape = alpha/sigma_multiplier,scale = sigma*sigma_multiplier)
  
  # for each cell use the latent expression and library size to simulate expression
  for(i in 1:n){
  
    Y[i] <- rpois(1,Li*lambdaj[i])
  }
  
  return(Y)
}

```

We perform the simulation for 1 individual/group and check the mean UMI.
```{r}
set.seed(11222024)
varying_factor <- seq(1, 2, by = 0.1)

gene_sim_matrix = c()
for(i in 1:length(varying_factor)){
  gene_sim <- sim_gene(1000,alpha,sigma,avg_li,sigma_multiplier=varying_factor[i])
  gene_sim_matrix <- cbind(gene_sim_matrix,gene_sim)
}
colnames(gene_sim_matrix) <- make.names(varying_factor)
colMeans(gene_sim_matrix)
```


We now save the matrix data for each number of individuals.
```{r, eval=F}
set.seed(11222024)

path = "/project2/gilad/awchen55/differentialDispersion/data/simulations/power_analysis"

varying_factor <- seq(1, 2, by = 0.1)
num_indv <- c(1,seq(5, 50, by = 5))

for(j in 1:length(num_indv)){
  gene_sim_matrix = c()
  num_indv_grp = 1000*num_indv[j]
  
  for(i in 1:length(varying_factor)){
    gene_sim <- sim_gene(num_indv_grp,alpha,sigma,avg_li,sigma_multiplier=varying_factor[i])
    gene_sim_matrix <- cbind(gene_sim_matrix,gene_sim)
    
  }
  colnames(gene_sim_matrix) <- make.names(varying_factor)
  write.csv(as.data.frame(gene_sim_matrix), file = file.path(path,paste("power_analysis_indv_",num_indv[j],".csv",sep="")), row.names = FALSE)
}

```


```{r}
path = "/project2/gilad/awchen55/differentialDispersion/data/simulations/power_analysis"
head(read.csv(file.path(path, "power_analysis_indv_50.csv")))
```

## **Estimating Variance**

We use the following equation to estimate variance by assuming a multivariate hypergeometric model for the data. [Kim et al.](https://www.cell.com/cell/fulltext/S0092-8674%2824%2901144-9) uses method of moments to estimate the variance.

$$
\hat{\sigma}_{g,HG}^2 = \frac{1}{n_{cells}}\sum_c \frac{Y^2_{cg} - Y_{cg}(1-q)}{N^2_cq^2- N_cq(1-q)} - \left( \frac{1}{n_{cells}}\sum_c\frac{Y_{cg}}{N_cq} \right)^2
$$
Where for $c$ cells and $g$ genes, $Y_{cg}$ is the observed transcript count, $N_c$ is the true total transcripts, $n_{cells}$ is the number of cells, and $q$ is the sampling efficiency. $N_cq$ is the library size.

## **Determine Significance**
We are assuming a two-sample problem between groups A and B, where A is the group with no effect size and B is the group with an effect size. Let $\Delta t$ be the observed difference between groups A and B, where $t$ is the statistic of interest. In our case, we are interested in differences in variance for a fixed mean. We perform bootstrapping for $B$ iterations to create a sampling distribution of $\Delta t_1,\dots,\Delta t_B$. To create the null distribution we subtract $\Delta t$ from $\Delta t_1,\dots,\Delta t_B$ to calculate $\Delta t_1^*,\dots,\Delta t_B^*$. This is the same approach used by Kim et al. We then compute the achieved significance level (ASL) as described by Efron and Tibshirani:

$$
\text{ASL} =
\begin{cases}
\frac{1}{B}\sum^B_{i=1}1(\Delta t_i^* \geq\Delta t) , & \text{if } \Delta t \geq 0 \\
    \frac{1}{B} \sum_{i=1}^B 1(\Delta t_i^* \leq\Delta t), & \text{if } \Delta t < 0
\end{cases}
\
$$

```{r}
sigma_sq_est <- function(df,n_cells,q,N_c){
  sigma_sq_term1 = (df^2 - df*(1-q))/(N_c^2*q^2 - N_c*q*(1-q))
  sigma_sq_term1 = colSums(sigma_sq_term1)/n_cells

  sigma_sq_term2 = df/(N_c*q)
  sigma_sq_term2 = (colSums(sigma_sq_term2)/n_cells)^2

  sigma_sq = sigma_sq_term1 - sigma_sq_term2
  
  
  return(sigma_sq)
}
```

## **Run Power Analysis**

We run the power analysis by simulating 1,000 times for $B=1,000$ bootstrapping iterations. We assume $q=0.4$. We test out 100 different effect sizes for the applied factor to the variance, spanned evenly between 1 and 2. 
```{r, include=TRUE, eval=FALSE}
n_sims = 100
B = 1000
n_cells = 1000
n_indv = 1
q = 0.4
library_size = 4064.29
N_c = library_size/q

varying_factor <- seq(1, 2, by = 100)
#num_indv <- c(1,seq(5, 50, by = 5))


n_sig <- rep(0,(length(varying_factor)-1))
for(j in 1:n_sims){
  gene_sim_matrix = c()
  num_indv_grp = n_cells*n_indv
  
  for(i in 1:length(varying_factor)){
    gene_sim <- sim_gene(num_indv_grp,alpha,sigma,avg_li,sigma_multiplier=varying_factor[i])
    gene_sim_matrix <- cbind(gene_sim_matrix,gene_sim)
    
  }
  colnames(gene_sim_matrix) <- make.names(varying_factor)
  
  sigma_sq_obs = sigma_sq_est(gene_sim_matrix,num_indv_grp,q,N_c)
  delta_t = sigma_sq_obs[2:length(sigma_sq_obs)] - sigma_sq_obs[1]
  
  
  asl_geq <- rep(0, (length(varying_factor)-1))
  asl_lt <- rep(0, (length(varying_factor)-1))
  for(i in 1:B){
    sample_idx <- sample(1:num_indv_grp,size = num_indv_grp,replace=TRUE)
    sample_df <- gene_sim_matrix[sample_idx,]
    
    sigma_sq_samp = sigma_sq_est(sample_df,num_indv_grp,q,N_c)
    delta_t_boot = sigma_sq_samp[2:length(sigma_sq_samp)] - sigma_sq_samp[1]
    delta_t_star = delta_t_boot - delta_t
    
    asl_geq = asl_geq + as.numeric(delta_t_star >= delta_t)
    asl_lt = asl_lt + as.numeric(delta_t_star <= delta_t)
    
  }
    
  
  asl <-c()
  for(i in 1:length(delta_t)){
    if(delta_t[i] >=0){
      asl <- c(asl,asl_geq[i])
    }
    else{
      asl <- c(asl,asl_lt[i])
    }
  }
  
  asl <- asl/B
  
  n_sig = n_sig + as.numeric(asl<0.05)
}

power_vec <- n_sig/n_sims
names(power_vec) <- varying_factor[2:length(varying_factor)]

path = "/project2/gilad/awchen55/differentialDispersion/data/simulations/power_analysis"

save(power_vec, file = file.path(path,paste("power_analysis_indv_",n_indv,".RData",sep="")))
```


### ***Power Analysis Across Effect Size***

We look at the power based on varying effect size for the number of individuals.
```{r}
# Initialize an empty list
data_list <- list()
path = "/project2/gilad/awchen55/differentialDispersion/data/simulations/power_analysis"

for (n_indv in 1:9) {
  # Load the RData file into a temporary environment
  temp_env <- new.env()
  load(file.path(path, paste("power_analysis_100ef_indv_", n_indv, ".RData", sep = "")), envir = temp_env)
  
  # Extract the power_vec and remove the last element
  powervec1 <- temp_env$power_vec
  powervec1 <- powervec1[-length(powervec1)]  # Remove the last element
  
  # Append the loaded data to the list with an 'id' column
  data_list[[n_indv]] <- data.frame(x = as.numeric(names(powervec1)), y = powervec1, id = factor(n_indv))
}

# Combine the data into a single data frame
combined_data <- do.call(rbind, data_list)

```

```{r,warning=F,message=F}
library(ggplot2)
# Colors for the graphs
#colors <- c("red", "blue", "green")

ggplot(combined_data, aes(x = x, y = y, color = as.factor(id), group = as.factor(id))) +
  geom_line(size = 1.2) + ylim(0,1)+
  labs(title = "Power Analysis Across Effect Size",
       x = "effect size", 
       y = "power",
       color = "Number of Individuals per Group") +
  #scale_color_manual(values = c("red", "blue", "green")) +  # Manually assign colors to each group
  theme_minimal() +
  theme(legend.position = "top") 
```


### ***Power Analysis Across Individuals***

```{r,warning=F,message=F}

ef_1.2 <- combined_data[round(combined_data$x, 6) == 1.202020, ]
ef_1.25 <- combined_data[round(combined_data$x, 6) == 1.252525, ]
ef_1.3 <- combined_data[round(combined_data$x, 6) == 1.303030, ]
ef_1.35 <- combined_data[round(combined_data$x, 6) == 1.353535, ]
ef_1.4 <- combined_data[round(combined_data$x, 6) == 1.404040, ]
ef_1.45 <- combined_data[round(combined_data$x, 6) == 1.454545, ]
ef_1.5 <- combined_data[round(combined_data$x, 6) == 1.505051, ]
combined_ef <- rbind(ef_1.2,ef_1.25,ef_1.3,ef_1.35,ef_1.4,ef_1.45,ef_1.5)

ggplot(combined_ef, aes(x = id, y = y, color = as.factor(round(x,2)), group = as.factor(round(x,2)))) +
  geom_line(size = 1.2) + ylim(0, 1) +
  labs(title = "Power Analysis Across Individuals",
       x = "number of individuals per group", 
       y = "power",
       color = "Effect Size") +
  #scale_color_manual(values = c("red", "blue", "green")) +  # Manually assign colors to each group
  theme_minimal() +
  theme(legend.position = "top") 
```

```{r, eval=F, include=F}

## Power Analysis for Identifying Significant Genes
#```{r}
# calculate alpha given mean expression and fixed sigma
calc_alpha <- function(mu, sigma){
  alpha = mu/sigma
  return(alpha)
}


# Function to simulate genes within a bin of mean expression
sim_bin <- function(n,p,phi,sigma_multiplier,Li,mean_expr_lwr,mean_expr_upr){
  
  # Simulate all genes with following parameters:
  # n:                number of cells
  # p:                number of genes
  # phi:              estimated dispersion parameter
  # phi_multiplier:   factor to increase dispersion parameter
  # Li:               library size
  # mean_expr_lwr:    lower bound of mean expression window
  # mean_expr_upr:    upper bound of mean expression window
 
  # Returns matrix of expression for n cells and p genes. 
  # Returns vector of index values for simulated dispersed genes.
  
  # initialize Y for bin of expression
  Y_bin <- matrix(NA,nrow=n,ncol=p)
  
  alpha_bin <- c()
  sigma_bin <- c()
  
  n_bin_split = 100
  # breakdown expression range into p values
  bin_expression <- seq(mean_expr_lwr,mean_expr_upr,length.out=n_bin_split)
  
  # randomly select p expression means
  bin_sim_idx <- sample.int(n_bin_split, n_bin_split, replace = TRUE)
  # randomly select 5% to be significantly dispersed
  bin_disp_idx <- sample.int(n_bin_split, 0.05*n_bin_split, replace = FALSE)
  # get expression means
  sim_expression_values <- bin_expression[bin_sim_idx]
  
  # simulate genes for each expression mean
  for(i in 1:n_bin_split){
    
    # get expression mean
    mu <- sim_expression_values[i]
    
    # calculate sigma parameter
    sigma <- mu*phi/Li
    sigma_bin <- c(sigma_bin,sigma)
    #sigma_disp <- mu*phi*phi_multiplier + 1
    
    # calculate alpha for fixed sigma based on expression mean
    alpha <- 1/phi#calc_alpha(mu,sigma)
    alpha_bin <- c(alpha_bin,alpha)
    #alpha_disp <- calc_alpha(mu,sigma_disp)
    
    # for dispersed genes multiply sigma by factor
    if(i %in% bin_disp_idx){
      
      Y_bin[,i] <- sim_gene(n,alpha,sigma,Li,sigma_multiplier)
    }
    else{
      Y_bin[,i] <- sim_gene(n,alpha,sigma,Li)
    }
  }
  
  return(list("Y_bin"=Y_bin, "disp_idx"=bin_disp_idx,"alpha_bin"=alpha_bin, "sigma_bin"=sigma_bin))
}

sim_Y <- function(n,p,phi,sigma_multiplier,Li,min_exp, max_exp){
  Y <- c()
  disp_idx <- c()
  alphas <- c()
  sigmas <- c()
  n_bins = p/100
  mean_intervals <- seq(min_exp, max_exp,length.out=(n_bins+1))
  for(i in 1:n_bins){
    
    mean_expr_lwr <- mean_intervals[i]
    mean_expr_upr <- mean_intervals[i+1]
    
    gene_sim <- sim_bin(n,n_bins,phi,sigma_multiplier,Li,mean_expr_lwr,mean_expr_upr)
    Y_bin <- gene_sim$Y_bin
    bin_disp_idx <- gene_sim$disp_idx + (i-1)*n_bins
    alpha_bin <- gene_sim$alpha_bin
    sigma_bin <- gene_sim$sigma_bin
    
    
    Y <- cbind(Y,Y_bin)
    disp_idx <- c(disp_idx,bin_disp_idx)
    alphas <- c(alphas,alpha_bin)
    sigmas <- c(sigmas, sigma_bin)
  }
  return(list("Y"=Y,"disp_idx"=disp_idx,"alpha"=alphas, "sigma"=sigmas))
}


cpm_norm <- function(Y){
  
  require(scTenifoldNet)
  Y_cpm_normalized <- t(cpmNormalization(t(Y)))
  Y_log_cpm_normalized <- log(t(cpmNormalization(t(Y))))
  
  Y_cv <- apply(Y_cpm_normalized, 2, sd)/apply(Y_cpm_normalized, 2, mean)
  Y_mean <- apply(Y_cpm_normalized, 2, mean)
  Y_cv_log <- apply(Y_log_cpm_normalized, 2, sd)/apply(Y_log_cpm_normalized, 2, mean)
  Y_mean_log <- apply(Y_log_cpm_normalized, 2, mean)
  
  return(list("Y_cpm_normalized"=Y_cpm_normalized, "Y_log_cpm_normalized" = Y_log_cpm_normalized, "Y_cv" = Y_cv, "Y_mean" = Y_mean, "Y_cv_log"=Y_cv_log, "Y_mean_log" = Y_mean_log))
}
#```


We simulate 1000 cells with 10,000 genes with a slightly variable mean (0.9-1.1 UMI/cell).
#```{r}
#### Simulate Y matrix for all genes
set.seed(11222024)

# Parameters
n=1000
p=10000

Y_varying<- sim_Y(n,p,phi,1.8,avg_li,0.9,1.1)
Y_cpm_normalized <- t(cpmNormalization(t(Y_varying$Y)))
#```


We look at a histogram of the example simulation.
#```{r}
hist(colMeans(Y_varying$Y), main = "", xlab="mean(UMI)")
#```




We now vary the applied factor from: 1,1.1,1.2,...,2.


#```{r}
set.seed(11222024)
library(scTenifoldNet)
applied_factor <- seq(1, 2, by = 0.1)
path = "/project2/gilad/awchen55/differentialDispersion/data/simulations/power_analysis"

for(i in 1:length(applied_factor)){
  Y_varying<- sim_Y(n,p,phi,applied_factor[i],avg_li,0.9,1.1)
}


#```

```









